---
title: "badmapProjectAnalyses"
author: "Jeanne"
date: "June 9, 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

##data wrangling packages (most part of the tidyverse)
library(stringr)
library(reshape2)
library(ggplot2)##plotting
library(plyr)
library(dplyr)
library(tidyr)
library(forcats)
library(scales)
library(modelbased)

#fonts
library(extrafont)
#font_import()
loadfonts(device = "win")




##analyses packages
library(lmerTest)
library(lme4)


options(scipen=1, digits=3)

```


#Load the data

##noun task and id task
```{r}
nounTask<-read.csv("exp1A_Nountask_masterFile.csv", header=TRUE, stringsAsFactors = FALSE)

ddply(nounTask, .(Condition), summarize, NumSubjects = length(unique(Subject)))


idTask<-read.csv("exp1A_idtask_masterFile.csv", header=TRUE, stringsAsFactors = FALSE)

ddply(idTask, .(condition), summarize, NumSubjects = length(unique(subject)))

```


#Data cleaning (eliminating outliers/bad performance participants)

##Noun task performance
```{r}

nounTask_mean_bySubj <-aggregate(nounAnswer~grammarType+Condition+Subject, nounTask, FUN="mean")
nouns_mean<-nounTask_mean_bySubj[nounTask_mean_bySubj$grammarType == "noun",]
nonnouns_mean<-nounTask_mean_bySubj[nounTask_mean_bySubj$grammarType == "notNoun",]

#poor performance participants based on accuracy on the task. 
badSubjNouns <-nouns_mean$Subject[nouns_mean$nounAnswer<0.5]
badSubjNotNouns <-nonnouns_mean$Subject[nonnouns_mean$nounAnswer>0.5]

length(unique(c(badSubjNotNouns, badSubjNouns))) #8 participants were excluded based on this. 

#poor performance participants based on rt results on the noun task. 
nounTask_rtmean<-aggregate(rt~grammarType+Condition, nounTask, FUN="mean")
nounTask_rtsd<-aggregate(rt~grammarType+Condition, nounTask, FUN="sd")
nounTask_rtmean$sd<-nounTask_rtsd$rt
nounTask_rtmean$sd2<-nounTask_rtmean$sd *2
nounTask_rtmean$thresholdmax<-nounTask_rtmean$rt+nounTask_rtmean$sd2
nounTask_rtmean$thresholdmin<-nounTask_rtmean$rt-nounTask_rtmean$sd2
  
nounTask_rtmean_bySubj <- aggregate(rt~grammarType+Condition+Subject, nounTask, FUN="mean")
  
##NOUNS
nouns_meanrt<-nounTask_rtmean[nounTask_rtmean$grammarType == "noun",]
names(nouns_meanrt)<-c("grammarType", "Condition","meanRT", "sd","sd2", "thresholdmax", "thresholdmin")
nouns_mean_bySubj<-nounTask_rtmean_bySubj[nounTask_rtmean_bySubj$grammarType=="noun",]

noun_rtAll<-merge(nouns_mean_bySubj, nouns_meanrt)

##bad participants based on performance on noun items
badSubjNounsRTmax<-noun_rtAll$Subject[noun_rtAll$rt>noun_rtAll$thresholdmax] #none
badSubjNounsRTmin<-noun_rtAll$Subject[noun_rtAll$rt<noun_rtAll$thresholdmin] #none


##NOT NOUNS
notNouns_meanrt<-nounTask_rtmean[nounTask_rtmean$grammarType=="notNoun",]
names(notNouns_meanrt)<-c("grammartype", "Condition","meanRT", "sd","sd2", "thresholdmax", "thresholdmin")
notNouns_mean_bySubj<-nounTask_rtmean_bySubj[nounTask_rtmean_bySubj$grammarType=="notNoun",]

notNoun_rtAll<-merge(notNouns_meanrt, notNouns_mean_bySubj)

##bad participants based on performance on nont noun items
badSubjNotNounsRTmax<-notNoun_rtAll$Subject[notNoun_rtAll$rt>notNoun_rtAll$thresholdmax] #none
badSubjNotNounsRTmin<-notNoun_rtAll$Subject[notNoun_rtAll$rt<notNoun_rtAll$thresholdmin] #none


##total bad participants based on performance on the noun task 
badNNNSubj<-c(badSubjNouns,badSubjNotNouns,badSubjNounsRTmax,badSubjNounsRTmin,badSubjNotNounsRTmax,badSubjNotNounsRTmin)

length(unique(badNNNSubj))

```

##ID task performance
```{r}
meanPercentSH<-aggregate(sAnswer ~ audio + subject, idTask, FUN="mean")

##measauring if the difference in sh answer between the first anad last step of the continuum is more than 50% (otherwise inndicating a relatively flat funciton, i.e., not doing the task right)

goodIDcalc<-meanPercentSH[meanPercentSH$audio %in% c("asee_shstep05","asee_shstep17"),]

goodIDcalcDiff<-spread(goodIDcalc, audio, sAnswer, fill = 0) %>%
                transmute(subject, Diff = asee_shstep05-asee_shstep17)

badSubjectID <- goodIDcalcDiff$subject[goodIDcalcDiff$Diff < 0.5]

length(badSubjectID) ## 21 participants performed poorly on the task based on "accuracy"

##RT results

idtask_meanRT_bySubj <- aggregate(rt~ subject+condition, idTask, FUN="mean")
idtask_meanRT<-aggregate(rt~condition, idTask, FUN="mean")
idtask_sdRT<-aggregate(rt~condition, idTask, FUN="sd")

idtask_meanRT$sd<-idtask_sdRT$rt
idtask_meanRT$sd2<-idtask_meanRT$sd *2
idtask_meanRT$thresholdmax<-idtask_meanRT$rt+idtask_meanRT$sd2
idtask_meanRT$thresholdmin<-idtask_meanRT$rt-idtask_meanRT$sd2
names(idtask_meanRT)<-c("condition","meanRT","sd","sd2","thresholdmax","thresholdmin")

idtask_RT<-merge(idtask_meanRT_bySubj, idtask_meanRT)


badSubjIDRTmin<-idtask_RT$subject[idtask_RT$rt>idtask_RT$thresholdmax]
badSubjIDRTmax<-idtask_RT$subject[idtask_RT$rt<idtask_RT$thresholdmin]
##No bad rt subject for id task either

##total bad participants based on performance on the id task

badIDSubj<-unique(c(badSubjectID,badSubjIDRTmin,badSubjIDRTmax))

```

total participants excluded: 

```{r}
badSubjAll <- unique(c(badNNNSubj,badIDSubj, "ABM06","BAM31","BAM02"))
#abm06 pressed the wrong buttons, #bam31 and BAM02 had a weird categorization function going up and down

length(badSubjAll)
```

##Cleaned up data sets  

```{r}
nounTask_good<-nounTask[!nounTask$Subject %in% badSubjAll,]
sampleSize_NT<-ddply(nounTask_good, .(Condition), summarize, NumSubjects = length(unique(Subject)))

idTask_good<-idTask[!idTask$subject %in% badSubjAll,]
sampleSize_ID<-ddply(idTask_good, .(condition), summarize, NumSubjects = length(unique(subject)))

##eliminating trials where RTs were higher than 5000ms or lower than 200ms
nounTask_good<-nounTask_good[!nounTask_good$rt > 5000,]
nounTask_good<-nounTask_good[!nounTask_good$rt <200,]

idTask_good<-idTask_good[!idTask_good$rt > 5000,]
idTask_good<-idTask_good[!idTask_good$rt < 200,]

#write.csv(idTask_good, file="idResultsGood.csv")
#write.csv(nounTask_good, file="nounResultsGood.csv")

```

#MEAN,PLOTS AND ANALYSES OF THE NOUN TASK RESULTS

##Accuracy for noun not noun
the fixed factors are: Condition, trial, grammar type (?)
random factors: subjects, words (items), trial, word type (filler vs critical)

```{r, echo=FALSE}
#mean 
nounTaskgd_mean <- aggregate(accuracy~wordType+Condition, nounTask_good, FUN="mean")
nounTaskgd_sd<- aggregate(accuracy~wordType+Condition, nounTask_good, FUN="sd")
nounTaskgd_mean$sd<-nounTaskgd_sd$accuracy

nounTaskgd_all<-merge(sampleSize_NT, nounTaskgd_mean)
nounTaskgd_all$sem<-nounTaskgd_all$sd/sqrt(nounTaskgd_all$NumSubjects)

#---------------------------------------------------------------------------------------#
aggregate(accuracy~wordType, nounTask_good, FUN="mean")
```


```{r}
#plot
ggplot(nounTaskgd_all, aes(wordType, accuracy))+
  geom_bar(stat = "identity", position="dodge", aes(fill=Condition))+
  geom_errorbar(aes(ymin=accuracy-sem, ymax=accuracy+sem, shape=Condition), width=.2,size=1, position=position_dodge(.9))+
  #geom_point(data = NNNRes_goodSubj, position =position_jitterdodge(jitter.width = 0,jitter.height = 0,dodge.width = .9), aes(x = type, y = Button.Pressed, shape = Condition),alpha=.3, size=2)+
  scale_fill_manual(values=c("#005a9c","#bf2c37","#008061","#b9ae35"),labels=c("Early Ambiguous","Early Bad Map","Late Ambiguous","Late Bad Map"))+
    scale_shape_discrete(labels=c("Early Ambiguous","Early Bad Map", "Late Ambiguous", "Late Bad Map"))+
  ylab("Accuracy")+
  xlab("Word type")+
  ylim(0,1)+
  theme_minimal(base_size = 20)+
    theme(plot.margin = unit(c(1,3,1,1),"lines"),
        text = element_text(family="Arial"),
        legend.position="right",
        axis.text.x = element_text(size=16),
        axis.text.y = element_text(size=16),
        plot.title = element_text(size=16))

#dev.off()

```

```{r, echo=FALSE}

##ANALYSES 
str(nounTask_good)
nounTask_good$Subject<-factor(nounTask_good$Subject)
nounTask_good$Condition<-factor(nounTask_good$Condition)
nounTask_good$wordType<-factor(nounTask_good$wordType)
nounTask_good$grammarType<-factor(nounTask_good$grammarType)


#accuracy not normal - binomial

##this is overall accuracy  (including nouns and non nouns)
##didn't converge with  a slope for wordtype
##DOESN"T CONVERGE"
#accuracyNNNexp1_model1<-glmer(accuracy~Condition*wordType+ Condition*grammarType+scale(trial)+(1+scale(trial)|word)+(1+wordType+grammarType+scale(trial)|Subject), family = "binomial", nounTask_good,glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))

#accuracyNNNexp1_model2<-glmer(accuracy~Condition*wordType+ Condition*grammarType+scale(trial)+(1|word)+(1+wordType+grammarType|Subject), family = "binomial", nounTask_good,glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))

#accuracyNNNexp1_model3<-glmer(accuracy~Condition*wordType+grammarType+scale(trial)+(1|word)+(1+wordType+grammarType|Subject), family = "binomial", nounTask_good,glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))

accuracyNNNexp1_model4<-glmer(accuracy~Condition*wordType+grammarType+scale(trial)+(1|word)+(1+wordType|Subject), family = "binomial", nounTask_good,glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))


accuracyNNNexp1_model5<-glmer(accuracy~Condition+wordType+grammarType+scale(trial)+(1|word)+(1+wordType|Subject), family = "binomial", nounTask_good,glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))


anova(accuracyNNNexp1_model4, accuracyNNNexp1_model5)
##interaction doesn't add to the model


summary(accuracyNNNexp1_model5)


nounTask_goodRLVL<-nounTask_good

nounTask_goodRLVL <- nounTask_good %>%
  mutate(Condition = relevel(Condition, ref = "BAM"))


accuracyNNNexp1_model5.bis<-glmer(accuracy~Condition+wordType+grammarType+scale(trial)+(1|word)+(1+wordType|Subject), family = "binomial", nounTask_goodRLVL,glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))

summary(accuracyNNNexp1_model5.bis)


accuracyNNNexp1_model6<-glmer(accuracy~wordType+grammarType+scale(trial)+(1|word)+(1+wordType|Subject), family = "binomial", nounTask_goodRLVL,glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))
##no differences between conditions. no differences for filler or grammar type. 

anova(accuracyNNNexp1_model5.bis, accuracyNNNexp1_model6)
```

#MEAN,PLOTS AND ANALYSES OF THE ID TASK RESULTS

```{r, echo=FALSE}
#mean 
idTask_gdMean <- aggregate(sAnswer~condition, idTask_good, FUN="mean")
idTask_gdSD<- aggregate(sAnswer~condition, idTask_good, FUN="sd")
#---------------EARLY AND LATE REPETITIONS------------------------------------------------------------------------#
idTask_good$phase[idTask_good$stepRepetition<=5]<- "Early"
idTask_good$phase[idTask_good$stepRepetition>5]<- "Late"

aggregate(sAnswer~condition+phase, idTask_good, FUN="mean")


#---------------------------------------------------------------------------------------#
```

##plot

```{r}
##baseline
 SHbyStep_mean<- aggregate(sAnswer~step+condition, idTask_good, FUN="mean")

SHbyStep_sd<- aggregate(sAnswer~step+condition, idTask_good, FUN="sd")

SHbyStep_mean$sd<-SHbyStep_sd$sAnswer

SHbyStep_tot<-merge(sampleSize_ID, SHbyStep_mean)

SHbyStep_tot$sem<-SHbyStep_tot$sd/sqrt(SHbyStep_tot$NumSubjects)

#png("allGroupsExp1B.png", units="in", width=12, height=6, res=300)

ggplot(SHbyStep_tot, aes(step, sAnswer))+
  geom_line(aes(color=condition, group = condition), size=1)+
    geom_errorbar(aes(ymin=sAnswer-sem,ymax=sAnswer+sem), width=.2,size=1,alpha=0.3, position=position_dodge(.9))+
  ylab("Percent 'S' answer")+
  xlab("Steps (from more S to more SH)")+
  scale_x_discrete(labels=c("asee_shstep05" = "step 5", "asee_shstep07" = "step 7",
                              "asee_shstep09" = "step 9", "asee_shstep11"="step 11", "asee_shstep13"="step 13",
                            "asee_shstep15"= "step 15", "asee_shstep17"= "step 17"))+
  scale_color_manual(values=c("#005a9c","#bf2c37","#008061","#b9ae35","#001f23"),labels=c("Early Ambiguous","Early Bad Map","Late Ambiguous","Late Bad Map","Baseline"))+
      theme_minimal(base_size = 20)+
    theme(plot.margin = unit(c(1,3,1,1),"lines"),
        text = element_text(family="Times New Roman"),
        legend.position="right",
        axis.text.x = element_text(size=16),
        axis.text.y = element_text(size=16),
        plot.title = element_text(size=16))+
  guides(linetype=FALSE)

#dev.off()
```



##modelling
```{r}
##make thigns factors

idTask_good$condition<- factor(idTask_good$condition)
idTask_good$phase<-factor(idTask_good$phase)
idTask_good$subject<-factor(idTask_good$subject)


idTask_good <- idTask_good %>%
  mutate(condition = relevel(condition, ref = "SSH"))

##take out two extreme steps
idTask_good_noFinalSteps<-idTask_good[!idTask_good$step %in% c(5, 17),]

idTask_good_noFinalSteps$Step_centered<-rescale(idTask_good_noFinalSteps$step, to = c(-0.5, 0.5))


##Accuracy


##nopre

accIDexp1_model1<-glmer(sAnswer~condition*Step_centered+scale(trial)+(1+step|subject),family="binomial",idTask_good_noFinalSteps,glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))

summary(accIDexp1_model1)

#accIDexp1_model1<-glmer(Button.Pressed~Condition*Step_centered+scale(Trial)+(1|Subject),family="binomial",finalIDRes_moreExcluded,glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))



accIDexp1_model2<-glmer(sAnswer~condition+Step_centered+scale(trial)+(1+step|subject),family="binomial",idTask_good_noFinalSteps,glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))


anova(accIDexp1_model1, accIDexp1_model2)

summary(accIDexp1_model2)



```



```{r}
##early passes only

modelEarly<-glmer(sAnswer~condition+Step_centered+scale(trial)+(1+step|subject),family="binomial",idTask_good_noFinalSteps[idTask_good_noFinalSteps$phase == "Early",],glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))

summary(modelEarly)


```
```{r}
modelLate<-glmer(sAnswer~condition+Step_centered+scale(trial)+(1|subject),family="binomial",idTask_good_noFinalSteps[idTask_good_noFinalSteps$phase == "Late",],glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))

summary(modelLate)


```

##Interaction analyses
```{r}

idTask_good_noFinalSteps$pronunciation[idTask_good_noFinalSteps$condition %in% c("AAM","BAM")]<-"ambiguous"
idTask_good_noFinalSteps$pronunciation[idTask_good_noFinalSteps$condition %in% c("ABM","BBM")]<-"badmap"
idTask_good_noFinalSteps$pronunciation[idTask_good_noFinalSteps$condition %in% c("SSH")]<-"none"

idTask_good_noFinalSteps$pronunciation<-as.factor(idTask_good_noFinalSteps$pronunciation)

idTask_good_noFinalSteps$position[idTask_good_noFinalSteps$condition %in% c("AAM","ABM")]<-"early"
idTask_good_noFinalSteps$position[idTask_good_noFinalSteps$condition %in% c("BAM","BBM")]<-"late"
idTask_good_noFinalSteps$position[idTask_good_noFinalSteps$condition %in% c("SSH")]<-"none"


idTask_good_noFinalStepsRLVL <- idTask_good_noFinalSteps %>%
  mutate(pronunciation = relevel(pronunciation, ref = "none"))

idTask_good_noFinalStepsRLVL$position<-as.factor(idTask_good_noFinalStepsRLVL$position)


idTask_good_noFinalStepsRLVL <- idTask_good_noFinalStepsRLVL %>%
  mutate(position = relevel(position, ref = "late"))



modelInteraction<-glmer(sAnswer~pronunciation*position+Step_centered+scale(trial)+(1+step|subject),family="binomial",idTask_good_noFinalStepsRLVL[idTask_good_noFinalStepsRLVL$phase == "Early",],glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))

summary(modelInteraction)


```

