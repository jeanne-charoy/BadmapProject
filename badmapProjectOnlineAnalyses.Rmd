---
title: "badmapProjectOnlineAnalyses"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

##data wrangling packages (most part of the tidyverse)
library(stringr)
library(reshape2)
library(ggplot2)##plotting
library(plyr)
library(dplyr)
library(tidyr)
library(forcats)
library(scales)
library(modelbased)

##analyses packages
library(lmerTest)
library(lme4)


options(scipen=1, digits=3)

```

#Load the data

##noun task, id task, baseline
```{r}
##NOUN TASK DATA
nounTask_Online<-read.csv("exp1Online_NNNRes.csv", header=TRUE, stringsAsFactors = FALSE)

ddply(nounTask_Online, .(condition), summarize, NumSubjects = length(unique(subject)))

##ID TASK DATA
idTask_Online<-read.csv("exp1Online_IDTaskRes.csv", header=TRUE, stringsAsFactors = FALSE)

ddply(idTask_Online, .(condition), summarize, NumSubjects = length(unique(subject)))

##BASELINE DATA
baselineTask_Online<-read.csv("exp1Online_BaselineRes.csv", header=TRUE, stringsAsFactors = FALSE)



allIDtaskres<-(rbind(idTask_Online, baselineTask_Online))

ddply(allIDtaskres, .(condition), summarize, NumSubjects = length(unique(subject)))

```
#eliminating trials that don't make sense (RTs > 5000ms or <200ms)
```{r}
##eliminating trials where RTs were higher than 5000ms or lower than 200ms
nounTask_Online<-nounTask_Online[!nounTask_Online$rt > 5000,]
nounTask_Online<-nounTask_Online[!nounTask_Online$rt <200,]

allIDtaskres<-allIDtaskres[!allIDtaskres$rt > 5000,]
allIDtaskres<-allIDtaskres[!allIDtaskres$rt < 200,]
```


##First going through the exclusion criteria based on characteristics of the participants (language background, audio equipment etc...)

```{r}
#####Did they report being normal of hearing or corrected to normal?#############################

##### EXPERIMENTAL GROUP

allIDtaskresHearing<-allIDtaskres$subject[allIDtaskres$hearing=="no"]

length(unique(allIDtaskresHearing)) ## 2 subjects excluded based on this



##Did they report English as part of their native language? 

allIDtaskresEnglish<-allIDtaskres$subject[!allIDtaskres$lang %in% c("english","biling")]

length(unique(allIDtaskresEnglish)) ## 104  subjects excluded based on this

#length(setdiff(allIDtaskresEnglish,allIDtaskresHearing))


##Did they report using headphones or earphones to complete the study

allIDtaskres_headphones<-allIDtaskres$subject[allIDtaskres$equip %in% c("Laptop/pc speakers","External speakers (cost $30 or less)", "External speakers (cost between $30 and $100)","External speakers (cost more than $100)")]

length(unique(allIDtaskres_headphones)) ## 198  subjects excluded based on this


#total bad subjects based on these

allBadCharacterisitcs<-unique(c(allIDtaskresHearing,allIDtaskresEnglish,allIDtaskres_headphones))

length(allBadCharacterisitcs) #250 for experimental + baseline data

nounTask_OnlineGd1<-nounTask_Online[!nounTask_Online$subject %in% allBadCharacterisitcs,]
idTask_OnlineGd1<-allIDtaskres[!allIDtaskres$subject %in% allBadCharacterisitcs,]

ddply(nounTask_OnlineGd1, .(condition), summarize, NumSubjects = length(unique(subject)))

ddply(idTask_OnlineGd1, .(condition), summarize, NumSubjects = length(unique(subject)))


```


##Cleaning data continued - excluding subjects based on task performance.  
###First, the Noun task  
Participants were excluded if they had less than 50% accuracy on the nouns and/or non nouns, or if their average RTs were +/- 2 sd from their group's mean

```{r, echo=FALSE}
#bad subjects based on Noun-not noun task. 

##mean for noun/not noun task (as a function of grammatical type and condition)
nnnMean<-aggregate(nounAnswer~grammarType+subject+condition, nounTask_OnlineGd1, FUN="mean" )

##eliminating subjects who answered "not noun" more than 50% of the time for noun items
nnn_MeanNoun<-nnnMean[nnnMean$grammarType == "noun",]

badNoun_subj<-as.character(nnn_MeanNoun$subject[nnn_MeanNoun$nounAnswer<0.50]) 

##eliminating subejcts who answered "noun" more than 50% of the time for non noun items
nnn_MeanNotNoun<-nnnMean[nnnMean$grammarType == "notnoun",]
badNotNoun_subj<-as.character(nnn_MeanNotNoun$subject[nnn_MeanNotNoun$nounAnswer>0.50])


##based on RTs.  

#nounTask_OnlineGd1<-nounTask_OnlineGd1[!nounTask_OnlineGd1$rt >5000,]
#nounTask_OnlineGd1<-nounTask_OnlineGd1[!nounTask_OnlineGd1$rt <200,]


nnnMean_RT<-aggregate(rt~grammarType+subject+condition, nounTask_OnlineGd1, FUN="mean" )

nnnAllMean_RT<-aggregate(rt~grammarType+condition, nounTask_OnlineGd1, FUN="mean" )
nnnSD_RT<-aggregate(rt~grammarType+condition, nounTask_OnlineGd1, FUN="sd" )

nnn_MeanNounRT<-nnnMean_RT[nnnMean_RT$grammarType == "noun",]
nnn_SDNounRT<-nnnSD_RT[nnnSD_RT$grammarType == "noun",]
nnn_MeanAllNounRT <- nnnAllMean_RT[nnnAllMean_RT$grammarType == "noun",]
nnn_MeanAllNounRT$sd2<-2*(nnn_SDNounRT$rt)

nnn_MeanAllNounRT$maxThreshold<-nnn_MeanAllNounRT$rt + nnn_MeanAllNounRT$sd2

###non nouns


nnn_MeanNonNounRT<-nnnMean_RT[nnnMean_RT$wordType == "notnoun",]
nnn_SDNonNounRT<-nnnSD_RT[nnnSD_RT$wordType == "notnoun",]
nnn_MeanAllNonNounRT <- nnnAllMean_RT[nnnAllMean_RT$wordType == "notnoun",]
nnn_MeanAllNonNounRT$sd2<-2*(nnn_SDNonNounRT$rt)

nnn_MeanAllNonNounRT$maxThreshold<-nnn_MeanAllNonNounRT$rt + nnn_MeanAllNonNounRT$sd2 

meanAllthreshold<-rbind(nnn_MeanAllNounRT, nnn_MeanAllNonNounRT)
names(meanAllthreshold)<-c("wordType","condition","meanGroupRT","sd2","maxThresh")

nnnMean_RTCheck<-merge(nnnMean_RT,meanAllthreshold)

badSubjeRT<-nnnMean_RTCheck$subject[nnnMean_RTCheck$rt>nnnMean_RTCheck$maxThresh] ## no bad subjects here. 

######################################
##all bad subj in NNN task
badSubjectNountask<-c(badNoun_subj,badNotNoun_subj,badSubjeRT)


```

###id task
```{r, echo=FALSE}
##bad subject based on ID task

##ID TASK

##mean S answer on the different steps for each condition and each subject
idMean<-aggregate(SAnswer~step+subject+condition, idTask_OnlineGd1, FUN="mean" )

#without condition
idMeanSubj<-aggregate(SAnswer~step+subject, idTask_OnlineGd1, FUN="mean" )
goodIDcalc<-idMeanSubj[idMeanSubj$step %in% c("step05","step17"),]

goodIDcalcDiff<-spread(goodIDcalc, step, SAnswer, fill = 0) %>%
                transmute(subject, Diff = step05-step17)

badSubjectIDT <- goodIDcalcDiff$subject[goodIDcalcDiff$Diff <= 0.5]

#exp1ID_step1<-idTask_OnlineGd1[idTask_OnlineGd1$step == "step05",]
#exp1ID_step1Mean<-aggregate(SAnswer~subject, exp1ID_step1, FUN="mean")
#exp1ID_step1_badsubj<-exp1ID_step1Mean$subject[exp1ID_step1Mean$SAnswer<=0.50]


##Rts
#idTask_OnlineGd1<-idTask_OnlineGd1[!idTask_OnlineGd1$rt>5000,]
#idTask_OnlineGd1<-idTask_OnlineGd1[!idTask_OnlineGd1$rt<200,]


idMeanRT<-aggregate(rt~subject+condition, idTask_OnlineGd1, FUN="mean" )
idMeanRTAll<-aggregate(rt~condition, idTask_OnlineGd1, FUN="mean" )
idSDRTAll<-aggregate(rt~condition, idTask_OnlineGd1, FUN="sd" )

idMeanRTAll$sd<-idSDRTAll$rt
idMeanRTAll$sd2<-2*idMeanRTAll$sd
idMeanRTAll$thresholdmax<-idMeanRTAll$rt+idMeanRTAll$sd2
idMeanRTAll$thresholdmin<-idMeanRTAll$rt-idMeanRTAll$sd2

names(idMeanRTAll)<-c("NNNcondition","mean","sd","sd2","thresholdmax","thresholdmin")

idMeanRT<-merge(idMeanRT, idMeanRTAll)

idbadsubjectRT<-idMeanRT$subject[idMeanRT$rt>idMeanRT$thresholdmax] ## one subject

badSubjectID<-unique(c(badSubjectIDT, idbadsubjectRT))

length(badSubjectID)

```



```{r}
##all bad subjects 

badSubjectExp1Online<-unique(c(badSubjectNountask,badSubjectID))

length(badSubjectExp1Online)


```

```{r}
#cleaned up data sets: 

nounTask_OnlineGdFinal<-nounTask_OnlineGd1[!nounTask_OnlineGd1$subject %in% badSubjectExp1Online,]

idTask_OnlineGdFinal<-idTask_OnlineGd1[!idTask_OnlineGd1$subject %in% badSubjectExp1Online,]
sampleSizeOnline<-ddply(idTask_OnlineGdFinal, .(condition), summarize, NumSubjects = length(unique(subject)))








ddply(nounTask_OnlineGdFinal, .(condition), summarize, NumSubjects = length(unique(subject)))



#write.csv(idTask_OnlineGdFinal, file="idOnlineResultsGood.csv")
#write.csv(nounTask_OnlineGdFinal, file="nounOnlineResultsGood.csv")
```


#MEAN,PLOTS AND ANALYSES OF THE NOUN TASK RESULTS

##Accuracy for noun not noun
the fixed factors are: Condition, trial, grammar type (?)
random factors: subjects, words (items), trial, word type (filler vs critical)

```{r, echo=FALSE}
nounTask_OnlineGdFinal$grammarTypebis[nounTask_OnlineGdFinal$grammarType=="noun"]<-1
nounTask_OnlineGdFinal$grammarTypebis[nounTask_OnlineGdFinal$grammarType=="notnoun"]<-0


nounTask_OnlineGdFinal$accuracy[nounTask_OnlineGdFinal$nounAnswer==nounTask_OnlineGdFinal$grammarTypebis]<-1
nounTask_OnlineGdFinal$accuracy[!nounTask_OnlineGdFinal$nounAnswer==nounTask_OnlineGdFinal$grammarTypebis]<-0

#mean 
nounTaskOnlinegd_mean <- aggregate(accuracy~grammarType+condition, nounTask_OnlineGdFinal, FUN="mean")
nounTaskOnlinegd_sd<- aggregate(accuracy~grammarType+condition, nounTask_OnlineGdFinal, FUN="sd")
nounTaskOnlinegd_mean$sd<-nounTaskOnlinegd_sd$accuracy

nounTaskOnlinegd_mean<-merge(sampleSizeOnline, nounTaskOnlinegd_mean)
nounTaskOnlinegd_mean$sem<-nounTaskOnlinegd_mean$sd/sqrt(nounTaskOnlinegd_mean$NumSubjects)

#---------------------------------------------------------------------------------------#
aggregate(accuracy~grammarType, nounTask_OnlineGdFinal, FUN="mean")
aggregate(accuracy~wordType, nounTask_OnlineGdFinal, FUN="mean")

mean(nounTask_OnlineGdFinal$accuracy)

```


```{r}

means_bySubj<-aggregate(accuracy~grammarType+subject, nounTask_OnlineGdFinal, FUN="mean")
#plot
ggplot(nounTaskOnlinegd_mean, aes(grammarType, accuracy))+
  geom_bar(stat = "identity", position="dodge", aes(fill=condition))+
  geom_point(data=means_bySubj, aes(grammarType, accuracy))+
#  geom_errorbar(aes(ymin=accuracy-sem, ymax=accuracy+sem, shape=condition), width=.2,size=1, position=position_dodge(.9))+
  scale_fill_manual(values=c("#005a9c","#bf2c37","#008061","#b9ae35"),labels=c("Early Ambiguous","Early Bad Map","Late Ambiguous","Late Bad Map"))+
    scale_shape_discrete(labels=c("Early Ambiguous","Early Bad Map", "Late Ambiguous", "Late Bad Map"))+
  ylab("Accuracy")+
  xlab("Word type")+
  ylim(0,1)+
  theme_minimal(base_size = 20)+
    theme(plot.margin = unit(c(1,3,1,1),"lines"),
        text = element_text(family="Arial"),
        legend.position="right",
        axis.text.x = element_text(size=16),
        axis.text.y = element_text(size=16),
        plot.title = element_text(size=16))


```


```{r, echo=FALSE}

##ANALYSES 
str(nounTask_OnlineGdFinal)
nounTask_OnlineGdFinal$subject<-factor(nounTask_OnlineGdFinal$subject)
nounTask_OnlineGdFinal$condition<-factor(nounTask_OnlineGdFinal$condition)
nounTask_OnlineGdFinal$wordType<-factor(nounTask_OnlineGdFinal$wordType)
nounTask_OnlineGdFinal$grammarType<-factor(nounTask_OnlineGdFinal$grammarType)


#same model as for Experiment 1 in lab
accuracyNNNexp1Online_model1<-glmer(accuracy~condition*wordType+grammarType+scale(trial)+(1|word)+(1+wordType|subject), family = "binomial", nounTask_OnlineGdFinal,glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))


accuracyNNNexp1Online_model2<-glmer(accuracy~condition+wordType+grammarType+scale(trial)+(1|word)+(1+wordType|subject), family = "binomial", nounTask_OnlineGdFinal,glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))


anova(accuracyNNNexp1Online_model1, accuracyNNNexp1Online_model2)
##interaction doesn't add to the model


summary(accuracyNNNexp1Online_model2)


nounTask_OnlineGdFinalRLVL<-nounTask_OnlineGdFinal

nounTask_OnlineGdFinalRLVL <- nounTask_OnlineGdFinal %>%
  mutate(condition = relevel(condition, ref = "bam"))


accuracyNNNexp1Online_model2.bis<-glmer(accuracy~condition+wordType+grammarType+scale(trial)+(1|word)+(1+wordType|subject), family = "binomial", nounTask_OnlineGdFinalRLVL,glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))

summary(accuracyNNNexp1Online_model2.bis)

accuracyNNNexp1Online_model3<-glmer(accuracy~wordType+grammarType+scale(trial)+(1|word)+(1+wordType|subject), family = "binomial", nounTask_OnlineGdFinalRLVL,glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))

anova(accuracyNNNexp1Online_model2.bis, accuracyNNNexp1Online_model3)

```



#MEAN AND ANALYSES OF THE ID TASK RESULTS

```{r, echo=FALSE}
#mean 
idOnlineTask_gdMean <- aggregate(SAnswer~condition, idTask_OnlineGdFinal, FUN="mean")
idOnlineTask_gdSD<- aggregate(SAnswer~condition, idTask_OnlineGdFinal, FUN="sd")


#---------------EARLY AND LATE REPETITIONS------------------------------------------------------------------------#

aggregate(SAnswer~condition+phase, idTask_OnlineGdFinal, FUN="mean")

aggregate(SAnswer~condition, idTask_OnlineGdFinal, FUN="mean")


#---------------------------------------------------------------------------------------#
```



##modelling
```{r}
##make thigns factors

idTask_OnlineGdFinal$condition<- factor(idTask_OnlineGdFinal$condition)
idTask_OnlineGdFinal$phase<-factor(idTask_OnlineGdFinal$phase)
idTask_OnlineGdFinal$subject<-factor(idTask_OnlineGdFinal$subject)


idTask_OnlineGdFinal <- idTask_OnlineGdFinal %>%
  mutate(condition = relevel(condition, ref = "baseline"))


idTask_OnlineGdFinal$step<-str_remove(idTask_OnlineGdFinal$step, "step")
idTask_OnlineGdFinal$step<-as.integer(idTask_OnlineGdFinal$step)

##take out two extreme steps
idOnlineTask_good_noFinalSteps<-idTask_OnlineGdFinal[!idTask_OnlineGdFinal$step %in% c(5, 17),]

idOnlineTask_good_noFinalSteps$Step_centered<-rescale(idOnlineTask_good_noFinalSteps$step, to = c(-0.5, 0.5))


##Percent S answer


##nopre

accIDexp1Online_model1<-glmer(SAnswer~condition*Step_centered+scale(trial)+(1+step|subject),family="binomial",idOnlineTask_good_noFinalSteps,glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))

summary(accIDexp1Online_model1)


accIDexp1Online_model2<-glmer(SAnswer~condition+Step_centered+scale(trial)+(1+step|subject),family="binomial",idOnlineTask_good_noFinalSteps,glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))


anova(accIDexp1Online_model1, accIDexp1Online_model2)

summary(accIDexp1Online_model2)



```



```{r}
##early passes only

modelOnlineEarly<-glmer(SAnswer~condition+Step_centered+scale(trial)+(1+step|subject),family="binomial",idOnlineTask_good_noFinalSteps[idOnlineTask_good_noFinalSteps$phase == "Early",],glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))

summary(modelOnlineEarly)


```

```{r}

##late passes only
modelOnlineLate<-glmer(SAnswer~condition+Step_centered+scale(trial)+(1|subject),family="binomial",idOnlineTask_good_noFinalSteps[idOnlineTask_good_noFinalSteps$phase == "Late",],glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))

summary(modelOnlineLate)


```


##Interaction analyses
```{r}



idOnlineTask_good_noFinalSteps$pronunciation[idOnlineTask_good_noFinalSteps$condition %in% c("aam","bam")]<-"ambiguous"
idOnlineTask_good_noFinalSteps$pronunciation[idOnlineTask_good_noFinalSteps$condition %in% c("abm","bbm")]<-"badmap"
idOnlineTask_good_noFinalSteps$pronunciation[idOnlineTask_good_noFinalSteps$condition %in% c("baseline")]<-"none"

idOnlineTask_good_noFinalSteps$pronunciation<-as.factor(idOnlineTask_good_noFinalSteps$pronunciation)

idOnlineTask_good_noFinalSteps$position[idOnlineTask_good_noFinalSteps$condition %in% c("aam","abm")]<-"early"
idOnlineTask_good_noFinalSteps$position[idOnlineTask_good_noFinalSteps$condition %in% c("bam","bbm")]<-"late"
idOnlineTask_good_noFinalSteps$position[idOnlineTask_good_noFinalSteps$condition %in% c("baseline")]<-"none"


idOnlineTask_good_noFinalStepsRLVL <- idOnlineTask_good_noFinalSteps %>%
  mutate(pronunciation = relevel(pronunciation, ref = "none"))

idOnlineTask_good_noFinalStepsRLVL$position<-as.factor(idOnlineTask_good_noFinalStepsRLVL$position)


idOnlineTask_good_noFinalStepsRLVL <- idOnlineTask_good_noFinalStepsRLVL %>%
  mutate(position = relevel(position, ref = "late"))



modelOnlineInteraction<-glmer(SAnswer~pronunciation*position+Step_centered+scale(trial)+(1|subject),family="binomial",idOnlineTask_good_noFinalStepsRLVL[idOnlineTask_good_noFinalStepsRLVL$phase == "Early",],glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))

summary(modelOnlineInteraction)


```